{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c179632f-83dd-4765-a747-76d73a4ad643",
   "metadata": {},
   "source": [
    "#### Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63e2c5-b172-4384-86e4-74392da41013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio ## library for reading and manipulating segy files \n",
    "import matplotlib.pyplot as plt ## library for plotting\n",
    "import numpy as np ## library for arrays\n",
    "from scipy import ndimage as ndi ## library for scientific calc and image processing\n",
    "from shutil import copyfile  ## for files management\n",
    "from skimage import exposure ## image processing\n",
    "import pandas as pd ## arrays, data handling\n",
    "import openpyxl ## excel file rader/write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c02bc9-9822-4d18-a0d6-3eedd5731df5",
   "metadata": {},
   "source": [
    "#### Importing the segy file and converting it into DataFrame (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55263f38-a792-47fb-a542-9d1ba6323d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='C:/Users/abdul/Downloads/seismic.segy'  # write path where seismic.segy file is downloaded\n",
    "f=segyio.open(filename, 'r+', strict=False, ignore_geometry=True) ## opening segy file for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedb57e-7f29-4aa8-a363-6a7015c9fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(filename))\n",
    "print(type(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e262e8-9809-46bd-9adb-31cd82261986",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [pd.DataFrame(f.trace[i] for i in range(0,120120,1))] ## getting all 1001 shots data, 1001*120 =120120 traces\n",
    "print(type(frames))\n",
    "result = pd.concat(frames)\n",
    "print(type(result))\n",
    "# result.to_excel('C:/Users/abdul/Downloads/ejaz1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026697df-ce2e-425d-b0d3-3396c5b05458",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg2=result.T ## transpose of data (1500 rows by 120120 columns (traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0754459-8ea2-45d8-8c5d-0575d47d8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg2 = pd.DataFrame(sg2.astype('float32')) # converting data to float64 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f1aa6-8649-4b6c-9bd3-1f77c4f25c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((sg2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7055b-66d2-4a21-8562-75c97989d10f",
   "metadata": {},
   "source": [
    "#### handling missing shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3db473-b321-4aea-b6bc-51e6bfa08beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis = [80,81,88,89,90,449,450,451,759,760,761] ## 1012 shots were recorded, of which 11 got missed\n",
    "slistc =list(range(1,1013)) \n",
    "slist=[0]*len(slistc)\n",
    "z=1\n",
    "for i in slistc:\n",
    "    if i not in mis:\n",
    "        slist[i-1]=z ## list containing the position of missed shots\n",
    "        z+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155db39d-fa8a-4504-8712-f7ad18e16e90",
   "metadata": {},
   "source": [
    "#### basic geometry and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2a8e0-98eb-4664-97cc-803447e5cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "so, dx, nt, fold = 262, 25, 120, 60 ## source offset to first trace, trace interval, no. of trace per shot, trace per CMP gather\n",
    "fs = 250  # sampling frequency\n",
    "dt = 1 / fs  # sampling interval\n",
    "td = 1500 * dt # total duration\n",
    "df = 1 / td ## frequency interval\n",
    "dw = 2 * np.pi * df ## frequency interval in rad/s\n",
    "t = np.arange(0, td, dt) ## time vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef64566-df69-4b16-b044-2d96fcc52022",
   "metadata": {},
   "source": [
    "#### Function for extracting the 60 fold CMP gather from the 60 shot data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebfff0-b4a8-4af2-935f-29b875d961a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extsg(sg2, k): ## sg2 is whole data set. k = shot number from 1001 shots \n",
    "    \n",
    "    idx = slist.index(k)\n",
    "    offsets = np.array([])\n",
    "    i=0\n",
    "    j=np.array([])\n",
    "    m=0\n",
    "    z=0\n",
    "    while i < fold:\n",
    "        if slist[i+idx]==0: ## if shot is missed then ignore it and continue checking for correct data \n",
    "            i+=1\n",
    "            z += -2\n",
    "            # print('mis')\n",
    "            continue\n",
    "        offsets=np.append(offsets,np.array([so + 2*i*dx]))  ## offsets to each receiver considering missed shots\n",
    "        j = np.append(j, np.array([k*nt-1 + m*118 +z])) ## index for picked trace from sg2 to form a cmp gather\n",
    "        m += 1\n",
    "        i += 1\n",
    "        \n",
    "    sg = pd.DataFrame(0.0, index=range(1500), columns=range(len(j))) \n",
    "    sg.iloc[:,0:len(j)] = sg2.iloc[:,j] ## extracted cmp gather from whole data \n",
    "    return sg, offsets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81310a0c-5d08-49f0-9515-99b12bb84862",
   "metadata": {},
   "source": [
    "#### Functions for NMO correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e5236-feae-4382-9cae-d41e45e00c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmo_correction(sgn, dt, offsets, vnmo): ## here velocities is single value for doing semblance analysis.\n",
    "    nmo = np.zeros_like(sgn)\n",
    "    nsamples = 1500 \n",
    "    times = np.arange(0, nsamples*dt, dt)\n",
    "    for i, t0 in enumerate(times):\n",
    "        for j, s0 in enumerate(offsets):\n",
    "            if t0*vnmo<=8:\n",
    "                break\n",
    "            tt = reflection_time(t0, s0, vnmo) ## reflection time calculated using t0, s0, and nmo velocity\n",
    "            amplitude = sample_trace(sgn[:, j], tt, dt) \n",
    "            if amplitude is not None: \n",
    "                nmo[i, j] = amplitude \n",
    "    return nmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b662dd-0e46-4f9e-9b3c-558275f0f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reflection_time(t0, x, vnmo): \n",
    "#     t = np.sqrt(t0**2 + x**2/vnmo**2) \n",
    "#     return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28007a72-8cc8-4c1e-a704-067ab73d4c5b",
   "metadata": {},
   "source": [
    "#### Modified reflection time to counter differential elevation in source and receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37abfe7-50a3-4247-bacb-e6f570f26c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflection_time(.47,262,1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2561a3-f9fa-43dd-94b5-3e52bf028bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_time(t0,s0,vnmo):\n",
    "    xd = 4*s0/(vnmo*t0-4)\n",
    "    s1= np.sqrt((vnmo*t0/2)**2+((s0+xd)/2)**2)\n",
    "    s2= np.sqrt((vnmo*t0/2-4)**2 + ((s0-xd)/2)**2)\n",
    "    t= (s1+s2)/vnmo\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1759dd-1af5-476a-8f2d-7604bdc7fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline \n",
    "\n",
    "def sample_trace(trace, time, dt): \n",
    "    before = int(np.floor(time/dt)) \n",
    "    N = trace.size \n",
    "    samples = np.arange(before-1, before + 3) \n",
    "    if any(samples < 0) or any(samples >= N): \n",
    "        amplitude = None \n",
    "    else: \n",
    "        times = dt*samples \n",
    "        amps = trace[samples] \n",
    "        interpolator = CubicSpline(times, amps) \n",
    "        amplitude = interpolator(time) # amplitude is ndarray of size 1 and shape == (). it is a scalar. cubicpline is used to interpolate value\n",
    "        ## of trace amplitude corresponding to reflection time.\n",
    "        amplitude = amplitude[()] # converting ndarray to numpy.float64\n",
    "    return amplitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b9356-dad9-4b64-84bf-13a304322172",
   "metadata": {},
   "source": [
    "#### Balancing the traces to rms level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4337ca-3993-4625-b7ae-63dc2ea5dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_trace(trace):\n",
    "    \"\"\"\n",
    "    Balance a single seismic trace to a common rms level.\n",
    "    \"\"\"\n",
    "    # Calculate the rms value of the trace\n",
    "    rms_value = np.sqrt(np.mean(trace ** 2))\n",
    "\n",
    "    # Scale the trace to the common rms level (e.g., 1.0)\n",
    "    balanced_trace = trace / rms_value\n",
    "\n",
    "    return balanced_trace\n",
    "\n",
    "def balance_seismic_data(seismic_data):\n",
    "    \"\"\"\n",
    "    Balance all traces in a seismic data set to a common rms level.\n",
    "    \"\"\"\n",
    "    balanced_seismic_data = np.zeros_like(seismic_data)\n",
    "\n",
    "    # Balance each trace individually\n",
    "    for i in range(seismic_data.shape[1]):\n",
    "        balanced_seismic_data[:, i] = balance_trace(seismic_data[:, i])\n",
    "\n",
    "    return balanced_seismic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954bd84-7e43-454c-a45a-753616e1d703",
   "metadata": {},
   "source": [
    "#### Function for semblance coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308187e-1f6c-4fa3-acd0-fa4fd8fccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem(nmc):\n",
    "    # k = 5\n",
    "    seb = np.zeros((1500))\n",
    "    for k in range(5,1495,1):\n",
    "        sumnum=0\n",
    "        sumden=0\n",
    "        for j in range(k-5,k+6,1):\n",
    "            sumnum += (np.sum(nmc[j,:]))**2\n",
    "            sumden += np.sum(nmc[j,:]**2)\n",
    "        if sumden != 0:\n",
    "            seb[k] = sumnum/sumden/nmc.shape[1]\n",
    "    return seb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133af365-b0d1-4ae0-990c-aea2f07e50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nmo_correction(sgn, dt, offsets, velocities):  ## here velocities is a vector containing velocity function with time.\n",
    "    # nmo = pd.DataFrame(0, index=range(sz[0]), columns=range(sz[1]))\n",
    "    nmo = np.zeros_like(sgn)\n",
    "    # print(nmo.iloc[1499,59])\n",
    "    nsamples = 1500 #cmp.shape[0] \n",
    "    times = np.arange(0, nsamples*dt, dt)\n",
    "    for i, t0 in enumerate(times):\n",
    "        for j, s0 in enumerate(offsets):\n",
    "            if t0*velocities[i]<=8:\n",
    "                # print('t0 = ', t0, ',vnmo= ', velocities, ',offset= ', x)\n",
    "                break\n",
    "            tt = reflection_time(t0, s0, velocities[i])\n",
    "            # print('t0 = ', t0, ',vnmo= ', velocities, ',offset= ', x, ', ref time = ', tt, ',xd = ', xd)\n",
    "            amplitude = sample_trace(sgn[:, j], tt, dt) \n",
    "            if amplitude is not None: \n",
    "                nmo[i, j] = amplitude \n",
    "    return nmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61c600f-1574-4e9a-bb21-4ce6095473e4",
   "metadata": {},
   "source": [
    "#### CMP stack analysis (20 CMPs) Old analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f010ee-aa87-4a3c-bb28-0dde255eea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_semb = 'C:/Users/abdul/Downloads/Ejaz/sembs.xlsx' ## path where semblance analysis matrices are saved (sembs.xlsx). Check \n",
    "## VikingAT_CMPstack jupyter notebook\n",
    "file_sgs = 'C:/Users/abdul/Downloads/Ejaz/sgs.xlsx' ## path where cmp gathers are saved (sgs.xlsx)\n",
    "cmp_stack=[]\n",
    "vel = np.arange(350,4501,25)\n",
    "\n",
    "for i in range(1,942,49):\n",
    "    print(i)\n",
    "    nsheet_name=f'sheet_{i}'\n",
    "\n",
    "    sg, offsets = extsg(sg2,i)\n",
    "    # sg = pd.read_excel(file_sgs, sheet_name=nsheet_name)\n",
    "\n",
    "    sg=sg.values\n",
    "    # print('sg done')\n",
    "    # print(sg[2,3])\n",
    "    sz = sg.shape\n",
    "    sgn = balance_seismic_data(sg) ## balancing the cmp gather\n",
    "\n",
    "\n",
    "### Plotting normalized cmp gather\n",
    "    \n",
    "    sn2 = np.zeros_like(sgn)\n",
    "    for k in range(sz[1]):\n",
    "        sn2[:,k] = sgn[:,k] + k*5.5\n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(sn2[:, :sz[1]], t, 'k')\n",
    "    ax1.invert_yaxis()  # Reverse the y-axis\n",
    "\n",
    "    # Extract x-tick positions\n",
    "    xtick_positions = np.mean(sn2[:, list(range(0,sz[1],8))], axis=0) \n",
    "    # Set x-tick marks and labels for the bottom axes\n",
    "    ax1.set_xticks(xtick_positions)\n",
    "    ax1.set_xticklabels(list(range(1,sz[1]+1,8)))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    # Set x-tick marks and labels for the top axes\n",
    "    xtick_positions_top = np.mean(sn2[:, list(range(0,sz[1],8))], axis=0) \n",
    "    ax2.set_xticks(xtick_positions_top)\n",
    "    ax2.set_xticklabels(offsets.tolist()[0:sz[1]:8])\n",
    "    \n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    \n",
    "    ax1.set_xlabel('Trace number')\n",
    "    ax2.set_xlabel('Offset from source (m)')\n",
    "    \n",
    "    # Set label for y-axis\n",
    "    ax1.set_ylabel('Time (s)')\n",
    "    plt.title('CMP Gather')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "### reading semblance values\n",
    "    semb = pd.read_excel(file_semb, sheet_name=nsheet_name, header=None)\n",
    "    semb=semb.values\n",
    "\n",
    "### Plotting semblance contour\n",
    "\n",
    "    fig, ax3 = plt.subplots()\n",
    "    contour = ax3.contourf(vel, t, semb / np.max(semb), cmap='magma')\n",
    "    ax3.invert_yaxis()  # Reverse the y-axis\n",
    "    ax3.set_ylabel('Time (s)')\n",
    "    ax3.set_xlabel('Velocity (m/s)')\n",
    "    \n",
    "    plt.title('Semblance Contour Plot')\n",
    "    \n",
    "    # Add colorbar using the result of contourf as the mappable\n",
    "    cbar = plt.colorbar(contour, ax=ax3, label='Semblance')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "#### Extracing and plotting velocity function with time (from semblance analysis/contour plot)\n",
    "    mxi = np.argmax(semb, axis=1)\n",
    "    # Find the maximum values in each row\n",
    "    mxv = semb[np.arange(len(semb)), mxi]\n",
    "    velm = vel[mxi] # velocity function\n",
    "\n",
    "    plt.plot(velm,t)\n",
    "    plt.gca().invert_yaxis()\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Velocity')\n",
    "    plt.ylabel('Time')\n",
    "    plt.title('Velocity Function')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### Final NMO correction using velocity function\n",
    "    final_nmc = f_nmo_correction(sgn, dt, offsets, velm)\n",
    "\n",
    "    \n",
    "### Plotting final NMO corrected CMP gather\n",
    "    sn3 = np.zeros_like(final_nmc)\n",
    "    for k in range(sz[1]):\n",
    "        sn3[:,k] = final_nmc[:,k]+k*5.5\n",
    "\n",
    "    fig, ax4 = plt.subplots()\n",
    "    ax4.plot(sn3[:, :sz[1]], t, 'k')\n",
    "    ax4.invert_yaxis()  # Reverse the y-axis\n",
    "\n",
    "    # Extract x-tick positions\n",
    "    xtick_positions = np.mean(sn3[:, list(range(0,sz[1],8))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "    # Set x-tick marks and labels for the bottom axes\n",
    "    ax4.set_xticks(xtick_positions)\n",
    "    ax4.set_xticklabels(list(range(1,sz[1]+1,8)))\n",
    "\n",
    "    ax5 = ax4.twiny()\n",
    "\n",
    "    # Set x-tick marks and labels for the top axes\n",
    "    xtick_positions_top = np.mean(sn3[:, list(range(0,sz[1],8))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "    ax5.set_xticks(xtick_positions_top)\n",
    "    ax5.set_xticklabels(offsets.tolist()[0:sz[1]:8])\n",
    "    \n",
    "    ax5.set_xlim(ax1.get_xlim())\n",
    "    \n",
    "    ax4.set_xlabel('Trace number')\n",
    "    ax5.set_xlabel('Offset from source (m)')\n",
    "    \n",
    "    # Set label for y-axis\n",
    "    ax4.set_ylabel('Time (s)')\n",
    "\n",
    "    plt.title('Final NMO Corrected CMP Gather')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### CMP Stacking \n",
    "    stack = np.sum(final_nmc, axis=1, keepdims=True)\n",
    "    stack_bal = balance_seismic_data(stack)\n",
    "    cmp_stack.append(stack_bal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afefa04-5402-4a9c-9194-28907df6e8ef",
   "metadata": {},
   "source": [
    "#### CMP stack analysis (20 CMPs) Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21a2dd-4ec0-4c06-8286-2cdf05ca64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_semb = 'C:/Users/abdul/Downloads/Ejaz/sembs.xlsx' ## path where semblance analysis matrices are saved (sembs.xlsx). Check \n",
    "## VikingAT_CMPstack jupyter notebook\n",
    "file_sgs = 'C:/Users/abdul/Downloads/Ejaz/sgs.xlsx' ## path where cmp gathers are saved (sgs.xlsx)\n",
    "cmp_stack=[]\n",
    "vel = np.arange(350,4501,25)\n",
    "\n",
    "for i in range(1,942,49):\n",
    "    print(i)\n",
    "    nsheet_name=f'sheet_{i}'\n",
    "\n",
    "    sg, offsets = extsg(sg2,i)\n",
    "    offsets=offsets.astype(int)\n",
    "    # sg = pd.read_excel(file_sgs, sheet_name=nsheet_name)\n",
    "\n",
    "    sg=sg.values\n",
    "    # print('sg done')\n",
    "    # print(sg[2,3])\n",
    "    sz = sg.shape\n",
    "    sgn = balance_seismic_data(sg) ## balancing the cmp gather\n",
    "\n",
    "\n",
    "### Plotting normalized cmp gather\n",
    "    \n",
    "    sn2 = np.zeros_like(sgn)\n",
    "    for k in range(sz[1]):\n",
    "        sn2[:,k] = sgn[:,k] + k*5.5\n",
    "\n",
    "\n",
    "    fig1, ax1 = plt.subplots(figsize=(1.5,1.5),dpi=400)\n",
    "    ax1.plot(sn2[:, :sz[1]], t, 'k',linewidth=0.15)\n",
    "    ax1.invert_yaxis()  # Reverse the y-axis\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "\n",
    "    # Extract x-tick positions\n",
    "    xtick_positions = np.mean(sn2[:, list(range(0,sz[1],8))], axis=0) \n",
    "    # Set x-tick marks and labels for the bottom axes\n",
    "    ax1.set_xticks(xtick_positions)\n",
    "    ax1.set_xticklabels(list(range(1,sz[1]+1,8)))\n",
    "    \n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    # Set x-tick marks and labels for the top axes\n",
    "    xtick_positions_top = np.mean(sn2[:, list(range(0,sz[1],8))], axis=0) \n",
    "    ax2.set_xticks(xtick_positions_top)\n",
    "    ax2.set_xticklabels(offsets.tolist()[0:sz[1]:8])\n",
    "    \n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=2.5, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Trace number', fontsize=3,labelpad=.9)\n",
    "    ax2.set_xlabel('Offset from source (m)', fontsize=3,labelpad=.9)\n",
    "    \n",
    "    # Set label for y-axis\n",
    "    ax1.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "    plt.title('CMP Gather', fontsize=4,pad=1)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "### reading semblance values\n",
    "    semb = pd.read_excel(file_semb, sheet_name=nsheet_name, header=None)\n",
    "    semb=semb.values\n",
    "\n",
    "### Plotting semblance contour\n",
    "\n",
    "    fig2, ax3 = plt.subplots(figsize=(1.8, 1.5),dpi=400)  # Set DPI here\n",
    "    \n",
    "    contour = ax3.contourf(vel, t, semb/np.max(semb), cmap='magma')\n",
    "    ax3.set_ylim(0, 6)\n",
    "    ax3.invert_yaxis()  # Reverse the y-axis\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "    \n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax3.spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    ax3.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "    ax3.set_xlabel('Velocity (m/s)', fontsize=3,labelpad=.9)\n",
    "    plt.title('Semblance Contour Plot and Vel Func', fontsize=4,pad=1.2)\n",
    "    \n",
    "    # Add colorbar using the result of contourf as the mappable\n",
    "    cbar = plt.colorbar(contour, ax=ax3, label='Semblance')\n",
    "\n",
    "    cbar.outline.set_linewidth(.3)\n",
    "    # Adjust the font size of the colorbar label\n",
    "    cbar.set_label('Semblance', fontsize=3,labelpad=.8)\n",
    "    \n",
    "    # Adjust the font size of the colorbar tick labels\n",
    "    cbar.ax.tick_params(labelsize=3, width=0.2, length=1.4,pad=.6)  # Adjust the labelsize as needed\n",
    "    \n",
    "    # Plot velocity function superimposed onto the contour plot\n",
    "    mxi = np.argmax(semb, axis=1)\n",
    "    mxv = semb[np.arange(len(semb)), mxi]\n",
    "    velm = vel[mxi]\n",
    "    ax3.plot(velm, t, 'w', linewidth=0.2)   # Plot velocity function in white color\n",
    "    # ax3.tick_params(axis='both', which='major', labelsize=3)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Final NMO correction using velocity function\n",
    "    final_nmc = f_nmo_correction(sgn, dt, offsets, velm)\n",
    "\n",
    "    \n",
    "### Plotting final NMO corrected CMP gather\n",
    "    sn3 = np.zeros_like(final_nmc)\n",
    "    for k in range(sz[1]):\n",
    "        sn3[:,k] = final_nmc[:,k]+k*5.5\n",
    "\n",
    "    fig3, ax4 = plt.subplots(figsize=(1.5, 1.5),dpi=400)\n",
    "    ax4.plot(sn3[:, :sz[1]], t, 'k',linewidth=0.15)\n",
    "    ax4.invert_yaxis()  # Reverse the y-axis\n",
    "    ax4.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax4.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    # Extract x-tick positions\n",
    "    xtick_positions = np.mean(sn3[:, list(range(0,sz[1],8))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "    # Set x-tick marks and labels for the bottom axes\n",
    "    ax4.set_xticks(xtick_positions)\n",
    "    ax4.set_xticklabels(list(range(1,sz[1]+1,8)))\n",
    "\n",
    "    ax5 = ax4.twiny()\n",
    "\n",
    "    # Set x-tick marks and labels for the top axes\n",
    "    xtick_positions_top = np.mean(sn3[:, list(range(0,sz[1],8))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "    ax5.set_xticks(xtick_positions_top)\n",
    "    ax5.set_xticklabels(offsets.tolist()[0:sz[1]:8])\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax5.spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    ax5.set_xlim(ax1.get_xlim())\n",
    "    ax5.tick_params(axis='both', which='major', labelsize=2.5, width=0.2, length=1.4,pad=.6)\n",
    "    \n",
    "    ax4.set_xlabel('Trace number', fontsize=3,labelpad=.9)\n",
    "    ax5.set_xlabel('Offset from source (m)', fontsize=3,labelpad=.9)\n",
    "    \n",
    "    # Set label for y-axis\n",
    "    ax4.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "\n",
    "    plt.title('Final NMO Corrected CMP Gather', fontsize=4,pad=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### CMP Stacking \n",
    "    stack = np.sum(final_nmc, axis=1, keepdims=True)\n",
    "    stack_bal = balance_seismic_data(stack)\n",
    "    cmp_stack.append(stack_bal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a34011-f32b-4173-bbe2-a0d9e9f679c6",
   "metadata": {},
   "source": [
    "# Updated velocity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408cdd8-779f-4f4c-8aea-bba9a0cf9010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def velf_gen(velm,v1,v2): # to define a velocity function\n",
    "    velf=np.zeros_like(t)\n",
    "\n",
    "\n",
    "    velf[0:int(0.5*250)] = 5 #velm[0:int(0.5*250)]\n",
    "    velf[int(0.5*250):int(4*250)+1] = v1 + (v2-v1)/(t[int(4*250)]-t[int(0.5*250)])*(t[int(0.5*250):int(4*250)+1]-t[int(0.5*250)])\n",
    "\n",
    "    for i in range(int(4*250)+1,int(5*250)+1):\n",
    "            velf[i] = velm[i] if velm[i] >= velf[i-1] and velm[i] < 2000 else velf[i-1]\n",
    "\n",
    "    for i in range(int(5*250)+1,int(6*250)):\n",
    "            velf[i] = velm[i] if velm[i] >= velf[i-1] and velm[i] < 2500 else velf[i-1]\n",
    "\n",
    "    return velf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f42fb-3711-44e6-bbcf-a5df9d3d1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_semb = 'C:/Users/abdul/Downloads/Ejaz/sembs.xlsx' ## path where semblance analysis matrices are saved (sembs.xlsx). Check \n",
    "## VikingAT_CMPstack jupyter notebook\n",
    "file_sgs = 'C:/Users/abdul/Downloads/Ejaz/sgs.xlsx' ## path where cmp gathers are saved (sgs.xlsx)\n",
    "cmp_stack1=[]\n",
    "vel = np.arange(350,4501,25)\n",
    "v1,v2 = 1500, 1600\n",
    "\n",
    "for i in range(1,942,49):\n",
    "    print(i)\n",
    "    nsheet_name=f'sheet_{i}'\n",
    "\n",
    "    sg, offsets = extsg(sg2,i)\n",
    "    offsets=offsets.astype(int)\n",
    "    # sg = pd.read_excel(file_sgs, sheet_name=nsheet_name)\n",
    "\n",
    "    sg=sg.values\n",
    "    # print('sg done')\n",
    "    # print(sg[2,3])\n",
    "    sz = sg.shape\n",
    "    sgn = balance_seismic_data(sg) ## balancing the cmp gather\n",
    "\n",
    "\n",
    "### Plotting normalized cmp gather\n",
    "    \n",
    "    sn2 = np.zeros_like(sgn)\n",
    "    for k in range(sz[1]):\n",
    "        sn2[:,k] = sgn[:,k] + k*5.5\n",
    "\n",
    "\n",
    "    fig1, ax1 = plt.subplots(figsize=(1.5,1.5),dpi=400)\n",
    "    ax1.plot(sn2[:, :sz[1]], t, 'k',linewidth=0.2)\n",
    "    ax1.invert_yaxis()  # Reverse the y-axis\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax1.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "\n",
    "    # Extract x-tick positions\n",
    "    xtick_positions = np.mean(sn2[:, list(range(0,sz[1],8))], axis=0) \n",
    "    # Set x-tick marks and labels for the bottom axes\n",
    "    ax1.set_xticks(xtick_positions)\n",
    "    ax1.set_xticklabels(list(range(1,sz[1]+1,8)))\n",
    "    \n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    # Set x-tick marks and labels for the top axes\n",
    "    xtick_positions_top = np.mean(sn2[:, list(range(0,sz[1],8))], axis=0) \n",
    "    ax2.set_xticks(xtick_positions_top)\n",
    "    ax2.set_xticklabels(offsets.tolist()[0:sz[1]:8])\n",
    "    \n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=2.5, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax2.spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    ax1.set_xlabel('Trace number', fontsize=3,labelpad=.9)\n",
    "    ax2.set_xlabel('Offset from source (m)', fontsize=3,labelpad=.9)\n",
    "    \n",
    "    # Set label for y-axis\n",
    "    ax1.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "    plt.title('CMP Gather', fontsize=4,pad=1)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "### reading semblance values\n",
    "    semb = pd.read_excel(file_semb, sheet_name=nsheet_name, header=None)\n",
    "    semb=semb.values\n",
    "\n",
    "### Plotting semblance contour\n",
    "\n",
    "    fig2, ax3 = plt.subplots(figsize=(1.8, 1.5),dpi=400)  # Set DPI here\n",
    "    \n",
    "    contour = ax3.contourf(vel, t, semb/np.max(semb), cmap='magma')\n",
    "    ax3.set_ylim(0, 6)\n",
    "    ax3.set_xlim(350, 4500)\n",
    "    ax3.invert_yaxis()  # Reverse the y-axis\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "    \n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax3.spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    ax3.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "    ax3.set_xlabel('Velocity (m/s)', fontsize=3,labelpad=.9)\n",
    "    plt.title('Semblance Contour Plot and Vel Func', fontsize=4,pad=1.2)\n",
    "    \n",
    "    # Add colorbar using the result of contourf as the mappable\n",
    "    cbar = plt.colorbar(contour, ax=ax3, label='Semblance')\n",
    "\n",
    "    cbar.outline.set_linewidth(.3)\n",
    "    # Adjust the font size of the colorbar label\n",
    "    cbar.set_label('Semblance', fontsize=3,labelpad=.8)\n",
    "    \n",
    "    # Adjust the font size of the colorbar tick labels\n",
    "    cbar.ax.tick_params(labelsize=3, width=0.2, length=1.4,pad=.6)  # Adjust the labelsize as needed\n",
    "    \n",
    "    # Plot velocity function superimposed onto the contour plot\n",
    "    \n",
    "\n",
    "    \n",
    "    mxi = np.argmax(semb, axis=1)\n",
    "    velm = vel[mxi]\n",
    "\n",
    "    # id1 = np.argmax(velm[int(0.3*250):int(1*250)]) + 75\n",
    "    # v1, t1 = velm[id1], t[id1]\n",
    "    \n",
    "    # id2 = np.argmax(velm[int(3*250):int(5.5*250)]) + 750\n",
    "    # v2, t2 = velm[id2], t[id2]\n",
    "\n",
    "    # v2=np.mean(velm[int(3*250):int(4.7*250)])\n",
    "    # t2=4\n",
    "    \n",
    "    # start_index = int(3 * 250)\n",
    "    # end_index = int(4.7 * 250)\n",
    "    \n",
    "    # # Create a boolean mask to filter out values below 1600 within the specified range\n",
    "    # mask = (velm[start_index:end_index] >= 1550)\n",
    "    \n",
    "    # # Calculate the mean using only the filtered values within the specified range\n",
    "    # v2 = np.mean(velm[start_index:end_index][mask])\n",
    "    \n",
    "    # t2=4\n",
    "\n",
    "    # velf = v1 + (v2-v1)/(t2-t1)*(t-t1)\n",
    "\n",
    "    velf = velf_gen(velm,v1,v2)\n",
    "    # velf=velm\n",
    "    v1 += 8\n",
    "    v2 += 8\n",
    "    \n",
    "    ax3.plot(velf, t, 'w', linewidth=0.2)   # Plot velocity function in white color\n",
    "    # ax3.scatter([v1, v2], [t1, t2], c=['r', 'g'],s=5)\n",
    "    # ax3.tick_params(axis='both', which='major', labelsize=3)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Final NMO correction using velocity function\n",
    "    final_nmc = f_nmo_correction(sgn, dt, offsets, velf)\n",
    "\n",
    "    \n",
    "### Plotting final NMO corrected CMP gather\n",
    "    sn3 = np.zeros_like(final_nmc)\n",
    "    for k in range(sz[1]):\n",
    "        sn3[:,k] = final_nmc[:,k]+k*5.5\n",
    "\n",
    "    fig3, ax4 = plt.subplots(figsize=(1.5, 1.5),dpi=400)\n",
    "    ax4.plot(sn3[:, :sz[1]], t, 'k',linewidth=0.25)\n",
    "    ax4.invert_yaxis()  # Reverse the y-axis\n",
    "    ax4.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax4.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "    # Extract x-tick positions\n",
    "    xtick_positions = np.mean(sn3[:, list(range(0,sz[1],8))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "    # Set x-tick marks and labels for the bottom axes\n",
    "    ax4.set_xticks(xtick_positions)\n",
    "    ax4.set_xticklabels(list(range(1,sz[1]+1,8)))\n",
    "\n",
    "    ax5 = ax4.twiny()\n",
    "\n",
    "    # Set x-tick marks and labels for the top axes\n",
    "    xtick_positions_top = np.mean(sn3[:, list(range(0,sz[1],8))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "    ax5.set_xticks(xtick_positions_top)\n",
    "    ax5.set_xticklabels(offsets.tolist()[0:sz[1]:8])\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax5.spines[axis].set_linewidth(0.5)\n",
    "    \n",
    "    ax5.set_xlim(ax1.get_xlim())\n",
    "    ax5.tick_params(axis='both', which='major', labelsize=2.5, width=0.2, length=1.4,pad=.6)\n",
    "    \n",
    "    ax4.set_xlabel('Trace number', fontsize=3,labelpad=.9)\n",
    "    ax5.set_xlabel('Offset from source (m)', fontsize=3,labelpad=.9)\n",
    "    \n",
    "    # Set label for y-axis\n",
    "    ax4.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "\n",
    "    plt.title('Final NMO Corrected CMP Gather', fontsize=4,pad=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "### CMP Stacking \n",
    "    stack = np.sum(final_nmc, axis=1, keepdims=True)\n",
    "    stack_bal = balance_seismic_data(stack)\n",
    "    cmp_stack1.append(stack_bal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179a5c8-1037-4fe5-8926-6042b7b1e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "off = np.array([0])\n",
    "k=1\n",
    "z=0\n",
    "for i in range(50,942,49):\n",
    "    idx = slist.index(i)\n",
    "    # print('idx= ',idx)\n",
    "    val = slistc[idx] - k\n",
    "    # print('\\n','val= ',val)\n",
    "    off=np.append(off,off[z]+val*25)\n",
    "    # print('\\n',off)\n",
    "    k=slistc[idx]\n",
    "    z+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a42d5-7190-48aa-9b25-e67bf9edf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_st = np.column_stack(cmp_stack1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2ee6c-e4f5-4004-80ad-2ed4247ce4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_pd=pd.DataFrame(cmp_st)\n",
    "excel_fp = 'C:/Users/abdul/Downloads/Ejaz/cmp_st.xlsx' ## path and name of excel file you want to assign for saving signal data\n",
    "exis_sn = 'Sheet1'\n",
    "cmp_pd.to_excel(excel_fp, sheet_name=exis_sn, index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196baef2-1ebe-4c3d-a950-52efdece2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_st = pd.read_excel('C:/Users/abdul/Downloads/Ejaz/cmp_st.xlsx', sheet_name='Sheet1', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ae984-6c63-40bc-bfbd-3c38de4758a6",
   "metadata": {},
   "source": [
    "#### Gain function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec7dda-8f74-456b-8142-bb3717832a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_exponential_gain(trace, exponent):\n",
    "    \"\"\"\n",
    "    Apply exponential gain function to a single seismic trace.\n",
    "    \n",
    "    Parameters:\n",
    "        trace (ndarray): Single seismic trace.\n",
    "        exponent (float): Exponent parameter for the exponential gain function.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: Seismic trace with exponential gain applied.\n",
    "    \"\"\"\n",
    "    # Compute exponential gain\n",
    "    gain = np.exp(exponent * t)\n",
    "    \n",
    "    # Apply gain to the trace\n",
    "    trace_with_gain = trace * gain\n",
    "\n",
    "    # trace_g = np.concatenate((trace_with_gain[0:int(3*250)+1],trace[int(3*250)+1:1500]),axis=0)\n",
    "    \n",
    "    return trace_with_gain\n",
    "\n",
    "def apply_exponential_gain_to_stack(cmp_st, exponent):\n",
    "    \"\"\"\n",
    "    Apply exponential gain function to each trace in a CMP stack.\n",
    "    \n",
    "    Parameters:\n",
    "        cmp_stk (ndarray): CMP stacked traces with shape (number of samples, number of traces).\n",
    "        exponent (float): Exponent parameter for the exponential gain function.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: CMP stacked traces with exponential gain applied.\n",
    "    \"\"\"\n",
    "    # Initialize array to store traces with gain applied\n",
    "    cmp_stk_with_gain = np.zeros_like(cmp_st)\n",
    "    \n",
    "    # Apply gain function to each trace\n",
    "    for i in range(cmp_st.shape[1]):\n",
    "        cmp_stk_with_gain[:, i] = apply_exponential_gain(cmp_st[:, i], exponent)\n",
    "    \n",
    "    return cmp_stk_with_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3bce2-0312-4e9f-8bd0-07a5c5029ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for exponential gain function\n",
    "exponent = .6  # Adjust as needed\n",
    "\n",
    "# Apply exponential gain function to CMP stack\n",
    "cmp_stk_gain = apply_exponential_gain_to_stack(cmp_st, exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c7476-1c93-482f-92c7-04e396588450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_stk = np.zeros_like(cmp_st)\n",
    "for i in range((cmp_st.shape[1])):\n",
    "    cmp_stk[:,i] = cmp_stk_gain[:,i]+i*15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ab3dc-40a0-43c9-ae09-7dbe5db83813",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(1.5,1.5),dpi=400)\n",
    "ax1.plot(cmp_stk[:, :cmp_stk.shape[1]], t, 'k',linewidth=0.15)\n",
    "# ax1.set_ylim(0, 3)  # Set the lower and upper limits\n",
    "ax1.invert_yaxis()  # Reverse the y-axis\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "\n",
    "\n",
    "ax1.tick_params(axis='both', which='major', labelsize=3, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax1.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "\n",
    "# Extract x-tick positions\n",
    "xtick_positions = np.mean(cmp_stk[:, list(range(0,cmp_stk.shape[1],3))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "# Set x-tick marks and labels for the bottom axes\n",
    "ax1.set_xticks(xtick_positions)\n",
    "ax1.set_xticklabels(list(range(1,cmp_stk.shape[1],3)))\n",
    "    \n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "# Set x-tick marks and labels for the top axes\n",
    "xtick_positions_top = np.mean(cmp_stk[:, list(range(0,cmp_stk.shape[1],3))], axis=0) #s2[:, [0, 9, 19, 29, 39, 49, 59]].mean().values\n",
    "ax2.set_xticks(xtick_positions_top)\n",
    "ax2.set_xticklabels(off.tolist()[0:cmp_stk.shape[1]:3])\n",
    "    \n",
    "ax2.set_xlim(ax1.get_xlim())\n",
    "ax2.tick_params(axis='both', which='major', labelsize=2.5, width=0.2, length=1.4,pad=.6)\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax2.spines[axis].set_linewidth(0.5)\n",
    "\n",
    "ax1.set_xlabel('CMP stacked trace number', fontsize=3,labelpad=.9)\n",
    "ax2.set_xlabel('CMP distance along survey line (m)', fontsize=3,labelpad=.9)\n",
    "\n",
    "# Set label for y-axis\n",
    "ax1.set_ylabel('Time (s)', fontsize=3,labelpad=.9)\n",
    "plt.title('CMP Stack Traces', fontsize=4,pad=1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
